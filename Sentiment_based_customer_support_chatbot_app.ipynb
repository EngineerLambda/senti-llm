{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Support Chatbot with Sentiment Analysis Functionality\n",
        "\n",
        "This application combines AI and sentiment analysis tools to function as a customer service bot, allowing users to submit reviews and receive immediate assistance. It is particularly useful for builders and service providers with a large customer base, as it reduces the need to hire additional customer service agents, thereby lowering costs and increasing profits.\n",
        "\n",
        "Tools Used:\n",
        "\n",
        "1. Hugging Face Pipeline: Provides the sentiment analysis model to evaluate the customer’s review before passing it on to the AI.\n",
        "\n",
        "\n",
        "2. Langchain: Serves as the AI platform for generating chatbot responses.\n",
        "\n",
        "\n",
        "3. Python: The entire application is built using Python.\n",
        "\n",
        "\n",
        "4. Gradio: Used to develop the chat interface.\n",
        "\n",
        "\n",
        "\n",
        "Users can simply enter their review in the provided space and submit it using a dedicated button. The AI then generates a response within seconds, based on the sentiment analysis.\n",
        "\n",
        "Tests:\n",
        "* Positive sentiment test\n",
        "![Positive sentiment test result](https://github.com/user-attachments/assets/3606c50b-5ccb-450f-9321-913a9e02c32d)\n",
        "\n",
        "* Negative sentiment test\n",
        "![Negative sentiment test result](https://github.com/user-attachments/assets/367b4d42-08e6-4f52-a087-8ba1755b594c)"
      ],
      "metadata": {
        "id": "THObLGEMd87L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yyKAAsx3Qe8W"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet huggingface_hub langchain_huggingface langchain langchain_community langchain_google_genai gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from transformers import pipeline\n",
        "from langchain_google_genai import GoogleGenerativeAI"
      ],
      "metadata": {
        "id": "idfOTnMjcqTq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass()"
      ],
      "metadata": {
        "id": "TXNy15Q0Rodb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f021c2-3403-4ebe-9a3c-bd7ce037fe1d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = getpass()"
      ],
      "metadata": {
        "id": "n70qoZJWaf62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd3d2fc-a78f-46b7-80fb-ef9b2fe013e6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "2d3DYhhvSGL_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "You are customer support AI assistant based for a company, your role is to make sure that customer reviews/comments and give befitting reponse\n",
        "You are to use customer's review and the sentiment obtained from the user review provided below.\n",
        "User review: {review}\n",
        "sentiment: {sentiment}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"review\", \"sentiment\"])"
      ],
      "metadata": {
        "id": "rNmUFocXTBUT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GoogleGenerativeAI(model=\"gemini-pro\")"
      ],
      "metadata": {
        "id": "r4z8walfS2YU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "OWE7P6_8T6gM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentiment analysis pipeline\n",
        "sentiment_analysis = pipeline(\"sentiment-analysis\", device=\"cuda:0\") #using default model checkpoint with the T4 GPU as device.\n",
        "\n",
        "# testing\n",
        "sample_text = \"I love this product, it works fine for me\"\n",
        "result = sentiment_analysis(sample_text)\n",
        "print(result[0][\"label\"])\n"
      ],
      "metadata": {
        "id": "HpozWxjbT_IN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa09e27-0951-4ed6-c015-77477e831a22"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POSITIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_llm_result(query):\n",
        "    sentiment = sentiment_analysis(query)[0][\"label\"]\n",
        "    return chain.invoke({\"review\": query, \"sentiment\": sentiment})"
      ],
      "metadata": {
        "id": "rXvcjQrgVBtW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_query = \"I love this product, it works fine for me\"\n",
        "get_llm_result(test_query)"
      ],
      "metadata": {
        "id": "_OYbegq1VZym",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9ec96c7e-f519-41b8-e9d4-8bcf3d66efa6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Thank you for your positive feedback! We're thrilled to hear that you're enjoying our product. We strive to provide our customers with high-quality products that meet their needs, and we're happy to know that we've succeeded in your case. If you have any further questions or comments, please don't hesitate to reach out.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# web app\n",
        "def chatbot_response(user_input):\n",
        "    return get_llm_result(user_input)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Sentiment based customer support Chatbot\")\n",
        "\n",
        "    input_textbox = gr.Textbox(label=\"Type in your review\", placeholder=\"Enter your review message...\")\n",
        "\n",
        "    submit_button = gr.Button(\"Send review\")\n",
        "    output_textbox = gr.Textbox(label=\"Chatbot's Response\")\n",
        "\n",
        "    submit_button.click(fn=chatbot_response, inputs=input_textbox, outputs=output_textbox)\n",
        "\n",
        "# Launch the Gradio interface\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "JkvLrvnIVdyR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "8e01ac68-15d8-4564-89ea-0c5eb6be76bc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d9375db6853d8893e9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d9375db6853d8893e9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}